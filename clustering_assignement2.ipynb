{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0944d1d4-77cc-4897-892b-161c238d06de",
   "metadata": {},
   "source": [
    "Q1. What is hierarchical clustering, and how is it different from other clustering techniques?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab672832-b458-451f-8373-057c4cc77b07",
   "metadata": {},
   "source": [
    "Hierarchical clustering is unsupervised machine learning techniques where data is not labeled but it finds patterns in the data and create groups that is cluster. Hierarchical clustering makes hierarchical shaped clusters example denodgram not centroid based cluster. It is different from other clusters in the sense that you dont have to specify initially how many clusters you need."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa0fe650-3b4a-4348-ab9a-14db2843766e",
   "metadata": {},
   "source": [
    "Q2. What are the two main types of hierarchical clustering algorithms? Describe each in brief."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99c99130-f88d-4e3e-bcec-12c2b5711bab",
   "metadata": {},
   "source": [
    "There are 2 types of hierarchical clustering algorithms: 1. Agglomerative  2. Divisive                                                                          \n",
    "1. Agglomerative: It is top down clustering technique. Each single data point is aggrated to form cluster. Each point is considered as separate cluster initially. Nearest point is found using similarity distance and new cluster is formed. This process is repeated until we get a single clsuter.\n",
    "2. Divisive: It is bottom up approach. Considers all points as 1 cluster initially. Sepeararte nearest point from each cluster.Keep on doing same process until we get a each point as separate cluster."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f203c94a-b479-4a5f-9d40-a5522416b65a",
   "metadata": {},
   "source": [
    "Q3. How do you determine the distance between two clusters in hierarchical clustering, and what are the\n",
    "common distance metrics used?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "532a6202-147b-4a82-bca6-a556c90ba78f",
   "metadata": {},
   "source": [
    "Distance between two clusters is determined using similarity measures. hierarchical clustering can be used with variety of data such as text, numeric etc. If data is textual than cosine similarity is used to find distance between 2 clusters and if data is numeric than euclidean or manhatten distance metric is used to calculate distance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac87d4ae-ed9f-4a6b-af5d-093aea53c850",
   "metadata": {},
   "source": [
    "Q4. How do you determine the optimal number of clusters in hierarchical clustering, and what are some\n",
    "common methods used for this purpose?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7188fbfb-1802-4378-9be6-35a62f99928d",
   "metadata": {},
   "source": [
    "To determine optimal number of clusters in hierarchical clustering dendogram is used."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6c08b67-31a1-4078-a338-681cefafea69",
   "metadata": {},
   "source": [
    "Q5. What are dendrograms in hierarchical clustering, and how are they useful in analyzing the results?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9259342a-596a-495a-b893-1f2ecc8a2e10",
   "metadata": {},
   "source": [
    "The dendrogram is a tree-like diagram that shows the hierarchical relationships between data points.\n",
    "By visually inspecting the dendrogram, you can identify the natural clusters by looking for significant jumps in the vertical lines.\n",
    "dendrogram is used to preserves the pairwise distances between the original data points.\n",
    "The closer the agglomerative coefficient is to 1, the better the dendrogram represents the actual distances."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fae22838-4018-4813-942c-b225ade13e38",
   "metadata": {},
   "source": [
    "Q6. Can hierarchical clustering be used for both numerical and categorical data? If yes, how are the\n",
    "distance metrics different for each type of data?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1cb7d6a-ac53-4130-9d26-7b457128e1ea",
   "metadata": {},
   "source": [
    "hierarchical clustering can be used with variety of data such as text, numeric,categorical etc. If data is textual or categorical than cosine similarity is used to find distance between 2 clusters and if data is numeric than euclidean or manhatten distance metric is used to calculate distance based on the application."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75eb1093-3326-483a-a82c-7a6119547af7",
   "metadata": {},
   "source": [
    "Q7. How can you use hierarchical clustering to identify outliers or anomalies in your data?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "798cf30b-55c5-4cda-a722-fca20b38dfdc",
   "metadata": {},
   "source": [
    "Use a hierarchical clustering algorithm (e.g., agglomerative or divisive) to cluster your data. This will create a dendrogram that illustrates the hierarchical relationships between data points.\n",
    "Choose a Cut-off Threshold:\n",
    "\n",
    "Determine a threshold distance or height at which you want to cut the dendrogram to form clusters. The choice of the threshold depends on the characteristics of your data and the level of granularity you want in identifying outliers.\n",
    "Identify Outliers in Isolated Clusters:\n",
    "\n",
    "Examine the resulting clusters after applying the cut-off threshold. Outliers are likely to be found in small clusters or as individual data points that are far from the main clusters.\n",
    "Analyze Subtrees and Branches:\n",
    "\n",
    "Investigate subtrees or branches of the dendrogram that are not part of the main clustering structure. Outliers may manifest as separate subtrees or branches that don't merge with the main clusters until later in the hierarchy.\n",
    "Distance Metrics and Dissimilarity Threshold:\n",
    "\n",
    "Use distance metrics (e.g., Euclidean distance) to measure dissimilarity between data points. Set a dissimilarity threshold beyond which data points are considered outliers. Points with dissimilarities above this threshold can be labeled as outliers.\n",
    "Silhouette Analysis:\n",
    "\n",
    "Compute silhouette scores for the data points in each cluster. Outliers may have lower silhouette scores compared to points in well-defined clusters.\n",
    "Density-Based Approaches:\n",
    "\n",
    "Apply density-based clustering techniques (e.g., DBSCAN) on the dissimilarity matrix or directly on the data. Outliers may be identified as data points that do not fall into any dense cluster.\n",
    "Domain-Specific Criteria:\n",
    "\n",
    "Consider domain-specific criteria for identifying outliers. Sometimes, anomalies are defined based on specific features or behaviors that might not be captured by generic clustering methods alone."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "",
   "name": ""
  },
  "language_info": {
   "name": ""
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
